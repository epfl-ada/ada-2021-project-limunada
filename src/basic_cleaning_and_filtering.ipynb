{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_cleaning_and_filtering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbUCbI8orIeL"
      },
      "source": [
        "## Installing and importing dependencies, mounting to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_fK6UaVrkcG",
        "outputId": "20d459de-4785-4988-841d-7c45b1ed0e86"
      },
      "source": [
        "!pip install pyarrow\n",
        "!pip install Wikidata\n",
        "!pip install google.drive\n",
        "\n",
        "# !pip install tld\n",
        "# !pip install aspect_based_sentiment_analysis\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.19.5)\n",
            "Requirement already satisfied: Wikidata in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: google.drive in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: google-auth-httplib2==0.0.3 in /usr/local/lib/python3.7/dist-packages (from google.drive) (0.0.3)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from google.drive) (1.8.0)\n",
            "Requirement already satisfied: dataclasses==0.6 in /usr/local/lib/python3.7/dist-packages (from google.drive) (0.6)\n",
            "Requirement already satisfied: google-auth-oauthlib==0.4.1 in /usr/local/lib/python3.7/dist-packages (from google.drive) (0.4.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->google.drive) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->google.drive) (1.35.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->google.drive) (3.0.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->google.drive) (1.15.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->google.drive) (0.17.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib==0.4.1->google.drive) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (21.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->google.drive) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->google.drive) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->google.drive) (0.2.8)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->google.drive) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->google.drive) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib==0.4.1->google.drive) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfD2Porh5YGV",
        "outputId": "1bd31f7a-1c90-45ae-a624-5e1f6a016f4c"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import json\n",
        "import os\n",
        "import bz2\n",
        "import itertools \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from wikidata.client import Client\n",
        "WIKI_CLIENT = Client()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_NXDgakYc8T"
      },
      "source": [
        "## Load Quotebank and discard 'None' speakers\n",
        "\n",
        "First, we want to load the Quotebank dataset (years 2015 - 2020) and discard \n",
        "all the quotes for which the most probable speaker is unidentified ('None').\n",
        "\n",
        "We save the resulting quotes into files whose names are formatted as 'quotes-no-nones-{year}.json.bz2'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ntF2MdCAvOM",
        "outputId": "f2ce4cc1-1d08-4534-8e27-c34fd389f2d4"
      },
      "source": [
        "# Iterate through the years of existing Quotebank files\n",
        "for year in range(2015, 2021):\n",
        "\n",
        "  path_to_file = f'/content/drive/MyDrive/Quotebank/quotes-{year}.json.bz2' \n",
        "  path_to_out = f'/content/drive/MyDrive/Quotebank_limunADA/quotes-no-nones-{year}.json.bz2'\n",
        "\n",
        "  # If the output file for the current year already exists, skip it\n",
        "  if os.path.isfile(path_to_out):\n",
        "    print(f'\\nFile for year {year} already exists. Moving on...')\n",
        "    continue\n",
        "\n",
        "  print(f'\\nExtracting non-None quotations for year {year}')\n",
        "\n",
        "  # Iterate through the quotes\n",
        "  with bz2.open(path_to_file, 'rb') as s_file:\n",
        "    with bz2.open(path_to_out, 'wb') as d_file:\n",
        "      for instance in s_file:\n",
        "\n",
        "        # loading a sample and checking the speaker\n",
        "        instance = json.loads(instance) \n",
        "        if instance['speaker'] == 'None':\n",
        "          continue\n",
        "\n",
        "        # writing in the new file\n",
        "        d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File for year 2015 already exists. Moving on...\n",
            "\n",
            "File for year 2016 already exists. Moving on...\n",
            "\n",
            "File for year 2017 already exists. Moving on...\n",
            "\n",
            "File for year 2018 already exists. Moving on...\n",
            "\n",
            "File for year 2019 already exists. Moving on...\n",
            "\n",
            "File for year 2020 already exists. Moving on...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6UKKz4GktIt"
      },
      "source": [
        "## Speaker attributes parquet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ASp9FBzpCX"
      },
      "source": [
        "# Load the provided parquet file with information (QIDs) about each of the speakers\n",
        "parquet_path = '/content/drive/MyDrive/Project datasets/speaker_attributes.parquet'\n",
        "speakers_attributes = pd.read_parquet(parquet_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "204qSRlMzpE2",
        "outputId": "b149bdc9-017e-484c-fa22-f6d4e704a83b"
      },
      "source": [
        "speakers_attributes.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aliases</th>\n",
              "      <th>date_of_birth</th>\n",
              "      <th>nationality</th>\n",
              "      <th>gender</th>\n",
              "      <th>lastrevid</th>\n",
              "      <th>ethnic_group</th>\n",
              "      <th>US_congress_bio_ID</th>\n",
              "      <th>occupation</th>\n",
              "      <th>party</th>\n",
              "      <th>academic_degree</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>candidacy</th>\n",
              "      <th>type</th>\n",
              "      <th>religion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Washington, President Washington, G. Washingt...</td>\n",
              "      <td>[+1732-02-22T00:00:00Z]</td>\n",
              "      <td>[Q161885, Q30]</td>\n",
              "      <td>[Q6581097]</td>\n",
              "      <td>1395141751</td>\n",
              "      <td>None</td>\n",
              "      <td>W000178</td>\n",
              "      <td>[Q82955, Q189290, Q131512, Q1734662, Q294126, ...</td>\n",
              "      <td>[Q327591]</td>\n",
              "      <td>None</td>\n",
              "      <td>Q23</td>\n",
              "      <td>George Washington</td>\n",
              "      <td>[Q698073, Q697949]</td>\n",
              "      <td>item</td>\n",
              "      <td>[Q682443]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Douglas Noel Adams, Douglas Noël Adams, Dougl...</td>\n",
              "      <td>[+1952-03-11T00:00:00Z]</td>\n",
              "      <td>[Q145]</td>\n",
              "      <td>[Q6581097]</td>\n",
              "      <td>1395737157</td>\n",
              "      <td>[Q7994501]</td>\n",
              "      <td>None</td>\n",
              "      <td>[Q214917, Q28389, Q6625963, Q4853732, Q1884422...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Q42</td>\n",
              "      <td>Douglas Adams</td>\n",
              "      <td>None</td>\n",
              "      <td>item</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Paul Marie Ghislain Otlet, Paul Marie Otlet]</td>\n",
              "      <td>[+1868-08-23T00:00:00Z]</td>\n",
              "      <td>[Q31]</td>\n",
              "      <td>[Q6581097]</td>\n",
              "      <td>1380367296</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[Q36180, Q40348, Q182436, Q1265807, Q205375, Q...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Q1868</td>\n",
              "      <td>Paul Otlet</td>\n",
              "      <td>None</td>\n",
              "      <td>item</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[George Walker Bush, Bush Jr., Dubya, GWB, Bus...</td>\n",
              "      <td>[+1946-07-06T00:00:00Z]</td>\n",
              "      <td>[Q30]</td>\n",
              "      <td>[Q6581097]</td>\n",
              "      <td>1395142029</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[Q82955, Q15982858, Q18814623, Q1028181, Q1408...</td>\n",
              "      <td>[Q29468]</td>\n",
              "      <td>None</td>\n",
              "      <td>Q207</td>\n",
              "      <td>George W. Bush</td>\n",
              "      <td>[Q327959, Q464075, Q3586276, Q4450587]</td>\n",
              "      <td>item</td>\n",
              "      <td>[Q329646, Q682443, Q33203]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Velázquez, Diego Rodríguez de Silva y Velázqu...</td>\n",
              "      <td>[+1599-06-06T00:00:00Z]</td>\n",
              "      <td>[Q29]</td>\n",
              "      <td>[Q6581097]</td>\n",
              "      <td>1391704596</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[Q1028181]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Q297</td>\n",
              "      <td>Diego Velázquez</td>\n",
              "      <td>None</td>\n",
              "      <td>item</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             aliases  ...                    religion\n",
              "0  [Washington, President Washington, G. Washingt...  ...                   [Q682443]\n",
              "1  [Douglas Noel Adams, Douglas Noël Adams, Dougl...  ...                        None\n",
              "2      [Paul Marie Ghislain Otlet, Paul Marie Otlet]  ...                        None\n",
              "3  [George Walker Bush, Bush Jr., Dubya, GWB, Bus...  ...  [Q329646, Q682443, Q33203]\n",
              "4  [Velázquez, Diego Rodríguez de Silva y Velázqu...  ...                        None\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQM6RpRJs75Y"
      },
      "source": [
        "## Enriching Quotebank using Wikidata\n",
        "We leverage the fact that we can easily enrich the Quotebank dataset by incorporating Wikidata into it. This is done by identifying the QID of the speaker (for a given quote), and then referring to the provided .parquet file with per-speaker information. \n",
        "\n",
        "The following columns are added to each quote information:    \n",
        "* age\n",
        "* nationality\n",
        "* party\n",
        "* academic degree\n",
        "* ethnicity\n",
        "* gender\n",
        "\n",
        "NOTE - before doing that, we have to adopt a way to disambiguate the relation between speaker names and their corresponding QIDs (since there can be multiple QIDs mapped to a single speaker name). The method that we adopted is taking the QID with the smallest number, implying that it was created the earliest. There are also other heuristics that could be used, but we stuck with this one throughout the process.\n",
        "\n",
        "### Wikidata API\n",
        "\n",
        "Here, we used the Wikidata API to get the desired QID-label mappings. However, in the meantime, ADA staff provided us with a big .csv file with all these human-interpretable labels, so we will move to that approach when working on Milestone 3. Anyways, we are showing this, since we implemented it before getting the files from TAs, it would be a waste otherwise. :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az0IbEbHwL7H"
      },
      "source": [
        "def get_min_qid(qids):\n",
        "  \"\"\"\n",
        "  Returns the QID with the smallest integer part.\n",
        "  \"\"\"\n",
        "  qids_int = [int(qid.replace('Q', '')) for qid in qids]\n",
        "  return f'Q{min(qids_int)}'\n",
        "\n",
        "\n",
        "def map_qids_to_labels(qids, wiki_client=WIKI_CLIENT):\n",
        "  \"\"\"\n",
        "  Given a set or list of QIDs, return a dictionary of format: {QID: label}\n",
        "  We get the labels for each QID using the Wikidata client.\n",
        "  \"\"\"\n",
        "  qids_labels_dict = dict()\n",
        "  for qid in qids:\n",
        "    try:\n",
        "      # Multilingual to basic string\n",
        "      qids_labels_dict[qid] = str(wiki_client.get(qid, load=True).label)\n",
        "    except Exception:\n",
        "      # In case the QID doesn't exist on Wikidata\n",
        "      print(f'Problem with {qid}. Skipping...')\n",
        "\n",
        "  return qids_labels_dict \n",
        "\n",
        "\n",
        "def add_wikidata_column_to_quote(\n",
        "    quote_data_original, \n",
        "    column_name, \n",
        "    speakers_attributes,\n",
        "    inplace=False,\n",
        "    ignore_existing=True,\n",
        "    is_qid=True\n",
        "    ):\n",
        "  \"\"\"\n",
        "  This functions takes as input a dictionary corresponding to a single quote \n",
        "  (with all the information that goes with it - 'speaker', 'qids', ...),\n",
        "  a column name that we wish to add to the quote, depending on its speaker,\n",
        "  and attributes for all speakers.\n",
        "  It finds the speaker QID, accesses its attributes, and either takes the raw \n",
        "  values from the desired column (is_qid==False), or queries those QIDs and\n",
        "  takes the corresponding human-interpretable labels (is_qid==True).\n",
        "  \"\"\"\n",
        "  if inplace:\n",
        "    quote_data = quote_data_original\n",
        "  else:\n",
        "    quote_data = quote_data_original.copy()\n",
        "\n",
        "  # If we're not OK with overwriting the existing column, raise an exception\n",
        "  if not ignore_existing:\n",
        "    if column_name in quote_data:\n",
        "      raise Exception(f'Provided column name \"{column_name}\" already exists!')\n",
        "\n",
        "  # Raise an exception if the column name doesn't exist in speaker attributes\n",
        "  if not column_name in speakers_attributes.columns:\n",
        "    err_msg = f'Provided column name \"{column_name}\" does not exist in the '\n",
        "    err_msg += 'provided speaker atttributes DataFrame!'\n",
        "    raise Exception(err_msg)\n",
        "\n",
        "  quote_data[column_name] = []\n",
        "\n",
        "  # Get the 'correct' speaker QID and the corresponding speaker attributes\n",
        "  speaker_qid = get_min_qid(quote_data['qids'])\n",
        "  curr_speaker_attributes = speakers_attributes[\n",
        "    speakers_attributes['id'] == speaker_qid\n",
        "    ]\n",
        "\n",
        "  # None check\n",
        "  if curr_speaker_attributes[column_name].values[0] is None:\n",
        "    return quote_data\n",
        "\n",
        "  # If the column value is expected to be QID, query it using Wikidata API\n",
        "  # If not, just take the raw values\n",
        "  if is_qid:\n",
        "    labels = map_qids_to_labels(\n",
        "        curr_speaker_attributes[column_name].values[0].tolist()\n",
        "        )\n",
        "  else:\n",
        "    labels_list = curr_speaker_attributes[column_name].values[0].tolist()\n",
        "    labels = {i: val for i, val in enumerate(labels_list)}\n",
        "  \n",
        "  # Assign the labels to the new column\n",
        "  for qid in labels:\n",
        "    quote_data[column_name].append(labels[qid])\n",
        "\n",
        "  return quote_data \n",
        "\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGOZDtERG4-a"
      },
      "source": [
        "### Example of enriching the data\n",
        "We provide a small example to demonstrate our Wikidata-enriching functions, to add the desired speaker attributes mentioned above. We divide them into columns that are represented as QIDs (needs querying) and that are not (does not need querying)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I_0iAptM45IC",
        "outputId": "120ce9e1-f96b-45ee-a033-976f647a53f8"
      },
      "source": [
        "# Define the columns that we want to add to the existing data\n",
        "QID_COLUMNS_TO_ADD = [\n",
        "  'nationality', 'party', 'ethnic_group', 'academic_degree', 'gender'\n",
        "  ]\n",
        "NON_QID_COLUMNS_TO_ADD = ['date_of_birth']\n",
        "\n",
        "# Number of instances to process in this example\n",
        "SAMPLES_TO_PROCESS = 10\n",
        "\n",
        "year = 2019\n",
        "path_to_file = f'/content/drive/MyDrive/Quotebank_limunADA/quotes-no-nones-{year}.json.bz2'\n",
        "running_df = pd.DataFrame()\n",
        "\n",
        "# Iterate through the quotes\n",
        "with bz2.open(path_to_file, 'rb') as s_file:\n",
        "  for i, instance in enumerate(s_file):\n",
        "    # Loading a sample and checking the speaker\n",
        "    instance = json.loads(instance) \n",
        "\n",
        "    # Add the columns that require querying with Wikidata API\n",
        "    for column_to_add in QID_COLUMNS_TO_ADD:\n",
        "      add_wikidata_column_to_quote(\n",
        "        instance, column_to_add, speakers_attributes, inplace=True\n",
        "        )\n",
        "    \n",
        "    # Add the columns that don't require querying\n",
        "    for column_to_add in NON_QID_COLUMNS_TO_ADD:\n",
        "      add_wikidata_column_to_quote(\n",
        "        instance, column_to_add, speakers_attributes, inplace=True, is_qid=False\n",
        "        )\n",
        "    \n",
        "    # Append the current instance to the running data frame\n",
        "    curr_df = pd.DataFrame([{k: str(v) for k, v in instance.items()}])\n",
        "    running_df = pd.concat([running_df, curr_df])\n",
        "\n",
        "    if i == SAMPLES_TO_PROCESS:\n",
        "      break \n",
        "\n",
        "running_df.head(SAMPLES_TO_PROCESS)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quoteID</th>\n",
              "      <th>quotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>qids</th>\n",
              "      <th>date</th>\n",
              "      <th>numOccurrences</th>\n",
              "      <th>probas</th>\n",
              "      <th>urls</th>\n",
              "      <th>phase</th>\n",
              "      <th>nationality</th>\n",
              "      <th>party</th>\n",
              "      <th>ethnic_group</th>\n",
              "      <th>academic_degree</th>\n",
              "      <th>gender</th>\n",
              "      <th>date_of_birth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-04-08-048753</td>\n",
              "      <td>It is immoral. It is harmful. It is hurtful.</td>\n",
              "      <td>President Donald Trump</td>\n",
              "      <td>['Q22686']</td>\n",
              "      <td>2019-04-08 16:22:00</td>\n",
              "      <td>44</td>\n",
              "      <td>[['President Donald Trump', '0.5802'], ['None'...</td>\n",
              "      <td>['https://www.mercedsunstar.com/news/business/...</td>\n",
              "      <td>E</td>\n",
              "      <td>['United States of America']</td>\n",
              "      <td>['Republican Party', 'Independence Party of Am...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['Bachelor of Science']</td>\n",
              "      <td>['male']</td>\n",
              "      <td>['+1946-06-14T00:00:00Z']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-05-15-053302</td>\n",
              "      <td>It is important for our equine science student...</td>\n",
              "      <td>Sally Johnson</td>\n",
              "      <td>['Q42336656']</td>\n",
              "      <td>2019-05-15 18:03:22</td>\n",
              "      <td>1</td>\n",
              "      <td>[['Sally Johnson', '0.5721'], ['None', '0.4279']]</td>\n",
              "      <td>['https://www.lanereport.com/113381/2019/05/qu...</td>\n",
              "      <td>E</td>\n",
              "      <td>['United States of America']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['female']</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-02-27-055406</td>\n",
              "      <td>It is important to many Native American tribes...</td>\n",
              "      <td>Rafael Ortega</td>\n",
              "      <td>['Q16672061', 'Q3417253', 'Q3417255', 'Q484101...</td>\n",
              "      <td>2019-02-27 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>[['Rafael Ortega', '0.7587'], ['None', '0.2413']]</td>\n",
              "      <td>['http://kstp.com/news/riverview-corridor-proj...</td>\n",
              "      <td>E</td>\n",
              "      <td>['Venezuela']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['male']</td>\n",
              "      <td>['+1991-05-15T00:00:00Z']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-12-08-023053</td>\n",
              "      <td>It is impossible, biologically, truly to `rest...</td>\n",
              "      <td>Barry Lopez</td>\n",
              "      <td>['Q809063']</td>\n",
              "      <td>2019-12-08 06:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>[['Barry Lopez', '0.8142'], ['None', '0.1858']]</td>\n",
              "      <td>['https://www.timescolonist.com/opinion/op-ed/...</td>\n",
              "      <td>E</td>\n",
              "      <td>['United States of America']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['male']</td>\n",
              "      <td>['+1945-01-06T00:00:00Z']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-02-21-000088</td>\n",
              "      <td>[ Chilton ] put it on a little tape recorder a...</td>\n",
              "      <td>Sam the Sham</td>\n",
              "      <td>['Q1971786']</td>\n",
              "      <td>2019-02-21 11:05:34</td>\n",
              "      <td>1</td>\n",
              "      <td>[['Sam the Sham', '0.6472'], ['None', '0.3278'...</td>\n",
              "      <td>['http://www.nashvillescene.com/music/features...</td>\n",
              "      <td>E</td>\n",
              "      <td>['United States of America']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['male']</td>\n",
              "      <td>['+1937-02-28T00:00:00Z']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-02-28-000093</td>\n",
              "      <td>... Darren just kind of kept fighting for me t...</td>\n",
              "      <td>Darren Lynn Bousman</td>\n",
              "      <td>['Q518770']</td>\n",
              "      <td>2019-02-28 04:00:57</td>\n",
              "      <td>1</td>\n",
              "      <td>[['Darren Lynn Bousman', '0.4538'], ['None', '...</td>\n",
              "      <td>['http://filmthreat.com/interviews/actors-sabr...</td>\n",
              "      <td>E</td>\n",
              "      <td>['United States of America']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['male']</td>\n",
              "      <td>['+1979-01-11T00:00:00Z']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-02-01-053787</td>\n",
              "      <td>It is indisputable that we don't have years to...</td>\n",
              "      <td>Peter Boyles</td>\n",
              "      <td>['Q7172917']</td>\n",
              "      <td>2019-02-01 16:07:34</td>\n",
              "      <td>1</td>\n",
              "      <td>[['Peter Boyles', '0.5464'], ['None', '0.3803'...</td>\n",
              "      <td>['https://ottawasun.com/news/local-news/corone...</td>\n",
              "      <td>E</td>\n",
              "      <td>['United States of America']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['male']</td>\n",
              "      <td>['+1943-10-17T00:00:00Z']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-06-18-000103</td>\n",
              "      <td>' DNA for property' is a special forensic adhe...</td>\n",
              "      <td>Amy Reid</td>\n",
              "      <td>['Q36427']</td>\n",
              "      <td>2019-06-18 03:12:14</td>\n",
              "      <td>1</td>\n",
              "      <td>[['Amy Reid', '0.5782'], ['None', '0.4218']]</td>\n",
              "      <td>['http://www.channel3000.com/news/dodge-county...</td>\n",
              "      <td>E</td>\n",
              "      <td>['United States of America']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['female']</td>\n",
              "      <td>['+1985-04-15T00:00:00Z']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-07-29-031592</td>\n",
              "      <td>It is just the ongoing hardening of the Brexit...</td>\n",
              "      <td>John Hardy</td>\n",
              "      <td>['Q18719463', 'Q23688353', 'Q2735767', 'Q53953...</td>\n",
              "      <td>2019-07-29 08:28:00</td>\n",
              "      <td>7</td>\n",
              "      <td>[['John Hardy', '0.7852'], ['None', '0.1985'],...</td>\n",
              "      <td>['https://www.cnbc.com/2019/07/29/reuters-amer...</td>\n",
              "      <td>E</td>\n",
              "      <td>['Canada']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['male']</td>\n",
              "      <td>['+1941-07-09T00:00:00Z']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-10-30-000114</td>\n",
              "      <td>[ Donaton's ] creative instincts and strategic...</td>\n",
              "      <td>Kelly Campbell</td>\n",
              "      <td>['Q6385969']</td>\n",
              "      <td>2019-10-30 16:38:39</td>\n",
              "      <td>1</td>\n",
              "      <td>[['Kelly Campbell', '0.6312'], ['None', '0.368...</td>\n",
              "      <td>['https://www.tubefilter.com/2019/10/30/digita...</td>\n",
              "      <td>E</td>\n",
              "      <td>['United States of America']</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['male']</td>\n",
              "      <td>['+1980-07-23T00:00:00Z']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             quoteID  ...              date_of_birth\n",
              "0  2019-04-08-048753  ...  ['+1946-06-14T00:00:00Z']\n",
              "0  2019-05-15-053302  ...                         []\n",
              "0  2019-02-27-055406  ...  ['+1991-05-15T00:00:00Z']\n",
              "0  2019-12-08-023053  ...  ['+1945-01-06T00:00:00Z']\n",
              "0  2019-02-21-000088  ...  ['+1937-02-28T00:00:00Z']\n",
              "0  2019-02-28-000093  ...  ['+1979-01-11T00:00:00Z']\n",
              "0  2019-02-01-053787  ...  ['+1943-10-17T00:00:00Z']\n",
              "0  2019-06-18-000103  ...  ['+1985-04-15T00:00:00Z']\n",
              "0  2019-07-29-031592  ...  ['+1941-07-09T00:00:00Z']\n",
              "0  2019-10-30-000114  ...  ['+1980-07-23T00:00:00Z']\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuHeMcylmfYN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}