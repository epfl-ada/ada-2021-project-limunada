{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADA_project_milestone_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6nxfIa9NuKa"
      },
      "source": [
        "# Sentiment-based graph of speakers\n",
        "\n",
        "In this notebook, we try to implement one of our ideas from Milestone 1 - designing a weighted, directed graph where each node represents an individual (a speaker from the Quotebank dataset), and an edge between two nodes depends on the sentiment with which they talk about each other in news articles. For example, if Donald Trump and Joe Biden are nodes in the graph, than the Trump -> Biden edge will depend on the sentiment in Trump's mentions of Biden, and vice-versa. In the end, this idea didn't end up being as feasible as we hoped... the main villain being sentiment analysis... Anyways, since we still hope to utilize sentiment analysis at some point, we plan to figure some ways of using it for Milestone 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ldq71ndNpgT"
      },
      "source": [
        "## Installing dependencies and importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_fK6UaVrkcG"
      },
      "source": [
        "!pip install aspect_based_sentiment_analysis"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfD2Porh5YGV",
        "outputId": "a098b04c-e8a3-4d0f-d0d7-40c85fa009dc"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import json\n",
        "import os\n",
        "import bz2\n",
        "import itertools \n",
        "\n",
        "import nltk \n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "import aspect_based_sentiment_analysis as absa\n",
        "nlp = absa.load()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n",
            "Some layers from the model checkpoint at absa/classifier-rest-0.2 were not used when initializing BertABSClassifier: ['dropout_379']\n",
            "- This IS expected if you are initializing BertABSClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertABSClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of BertABSClassifier were not initialized from the model checkpoint at absa/classifier-rest-0.2 and are newly initialized: ['dropout_37']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c2ImPYYQYfV"
      },
      "source": [
        "## Inspecting sentiment analysis models\n",
        "\n",
        "Let's first try out a few pre-trained models for sentiment analysis that can be used for this task and see how they behave. We'll do this on a made-up quote, that is used only to better illustrate model behaviours and justify our logic. If we imagine that this is a quote by Donald Trump, and we're computing the edge weight for the Trump-Hillary relation, we can clearly see that the sentiment should be pretty negative.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3me4ceoQXe4"
      },
      "source": [
        "sample_quote = 'I love myself because I am pretty but I really hate Hillary. '\n",
        "sample_quote += 'My brother is a very smart man.'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-akH3KxBZeU-"
      },
      "source": [
        "### NLTK Sentiment Intensity Analyzer \n",
        "\n",
        "Basic sentiment analysis that takes into account the whole given sentence and computes the overall sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ejR6DLcRnnn",
        "outputId": "a8a2c16b-cb31-4219-a2bd-519ac2394fc0"
      },
      "source": [
        "ABBREVIATIONS = {'neu': 'neutral', 'neg': 'negative', 'pos': 'positive'}\n",
        "\n",
        "# Compute sentiment polarity scores using the NLTK model\n",
        "nltk_scores = sia.polarity_scores(sample_quote)\n",
        "\n",
        "for abbr, sentiment_str in ABBREVIATIONS.items():\n",
        "  print(f'{sentiment_str}: {nltk_scores[abbr]}') "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral: 0.437\n",
            "negative: 0.218\n",
            "positive: 0.345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG90R5zbcXt6"
      },
      "source": [
        "### Aspect Based Sentiment Analysis\n",
        "\n",
        "A modified version of the sentiment analysis model that also takes as input the 'aspects', or target words on which we would like to focus our analysis (in this case 'Hillary')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBLjvNzbXG8m",
        "outputId": "cd750264-1e0d-4f8b-c6ee-4e821731dbe3"
      },
      "source": [
        "SENTIMENT_INDEXING = {'neutral': 0, 'negative': 1, 'positive': 2}\n",
        "ASPECTS = ['Hillary']\n",
        "\n",
        "# Compute sentiment scores using the ABSA model, \n",
        "# taking 'Hillary' as the aspect word\n",
        "task = nlp(text=(sample_quote), aspects=ASPECTS)\n",
        "absa_scores = task.examples[0].scores\n",
        "\n",
        "for sentiment_str, ind in SENTIMENT_INDEXING.items():\n",
        "  print(f'{sentiment_str}: {absa_scores[ind]:.3f}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral: 0.002\n",
            "negative: 0.991\n",
            "positive: 0.007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mizBxCd9cjQh"
      },
      "source": [
        "The previous example successfully showes the reason that we decided to opt for aspect-based sentiment analysis. Namely, as we could expect, a given quote doesn't necessarily contain mentions of only one person, nor does it have to contain one 'type' of sentiment. Given our desired use-case, where we'd like to assess the sentiment of the speaker towards another person (object), basic sentiment analysis over the whole sentence doesn't make much sense. So, in the made-up quote above, we give an example of how the overall sentiment of a sentence can be mostly positive (containing a couple of positive thoughts towards some topics), but still be pretty negative towards our topic (person) of interest! That is where the aspect-based sentiment analysis really excels compared to the basic approach.\n",
        "\n",
        "### Problem with ABSA\n",
        "\n",
        "Sadly, the model that showed more promise, came out as very bad in scaling up to the number of mentions, to the point where it is impossible to use it. That is demonstrated using the same made-up quote, just passed through the model $N=20$ times. We measure the execution times of the model from NLTK and the ABSA model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tI3yua_u4s5",
        "outputId": "7ccb2d52-7844-4ba4-ac4b-c6daacd8ea29"
      },
      "source": [
        "import time \n",
        "N_ITERS = 20\n",
        "\n",
        "# ABSA\n",
        "# Start time measurement\n",
        "start_time = time.time()\n",
        "\n",
        "for iter in range(N_ITERS):\n",
        "  task = nlp(text=(sample_quote), aspects=ASPECTS)\n",
        "\n",
        "# End time measurement and compute elapsed time\n",
        "end_time = time.time()\n",
        "elapsed = np.round(end_time - start_time, 2)\n",
        "print(f'ABSA model execution time for {N_ITERS} iterations: {elapsed} s')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABSA model execution time for 20 iterations: 17.71 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBHn0CNLv3hT",
        "outputId": "c1cfb745-6a08-489e-9e14-743008a079d8"
      },
      "source": [
        "N_ITERS = 20\n",
        "\n",
        "# NLTK\n",
        "# Start time measurement\n",
        "start_time = time.time()\n",
        "\n",
        "for iter in range(N_ITERS):\n",
        "  scores = sia.polarity_scores(sample_quote)\n",
        "\n",
        "# End time measurement and compute elapsed time\n",
        "end_time = time.time()\n",
        "elapsed = np.round(end_time - start_time, 2)\n",
        "print(f'NLTK model execution time for {N_ITERS} iterations: {elapsed} s')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK model execution time for 20 iterations: 0.01 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymK-bLZWwFfC"
      },
      "source": [
        "After showing this, it is needless to say that we are stepping away from the ABSA model ( 🐌 ), but with some hopes of maybe finding an alternative for Milestone 3. In the meantime, let's try what the basic sentiment analyzer form NLTK gives us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgiB4N-zDDVW"
      },
      "source": [
        "## Constructing the person-person graph \n",
        "\n",
        "Let's now construct the aforementioned graph of individuals and see what the edges will look like based on sentiment analysis between speakers. The graph contains just 3 nodes - Donald Trump, Hillary Clinton, and Barack Obama. As shown later, the year we are focusing on in this example is 2016, which was the year when Donald Trump became president, running against Clinton."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuimrAzsDItz"
      },
      "source": [
        "# Define the nodes as a dictionary of format {QID: name}\n",
        "nodes_qids = {\n",
        "    'Q22686': 'Donald Trump', \n",
        "    'Q6294': 'Hillary Clinton', \n",
        "    'Q6279': 'Barack Obama',\n",
        "    }\n",
        "nodes_qids_set = set(nodes_qids.keys())\n",
        "\n",
        "# Initialize the node-quote dictionary\n",
        "quotes_per_node = {k: [] for k in nodes_qids}\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTWxNWo8Dfxn"
      },
      "source": [
        "# Take the quotes of interest (assigned to the individuals defined as nodes)\n",
        "SAMPLES_TO_PROCESS = 3e6\n",
        "year = 2016\n",
        "path_to_file = f'/content/drive/MyDrive/Quotebank_limunADA/quotes-no-nones-{year}.json.bz2' \n",
        "\n",
        "print(f'\\nExtracting quotes per node for year {year}\\n')\n",
        "\n",
        "with bz2.open(path_to_file, 'rb') as s_file:\n",
        "  for instance_cnt, instance in enumerate(s_file):\n",
        "    # Loading a sample\n",
        "    instance = json.loads(instance) \n",
        "    \n",
        "    # Take the intersection of the set of QIDs that we defined as nodes, \n",
        "    # and the speaker QIDs of the current quote. If there is an intersection,\n",
        "    # take its first element (there should only be one anyways)\n",
        "    qids_intersect = nodes_qids_set.intersection(set(instance['qids']))\n",
        "    if len(qids_intersect) > 0:\n",
        "      curr_qid = qids_intersect.pop()\n",
        "      quotes_per_node[curr_qid].append(instance['quotation'])\n",
        "\n",
        "    if instance_cnt % 100000 == 0:\n",
        "      print(f'Instance {instance_cnt}')\n",
        "    \n",
        "    if instance_cnt == int(SAMPLES_TO_PROCESS):\n",
        "      break"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyAzKy9FtBc8"
      },
      "source": [
        "### Computing graph edges\n",
        "\n",
        "In order to compute the edge weights between certain nodes, we need to define the ways of quantifying the sentiments between them. We assign weights to each of the types of sentiments and aggregate that into a final score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuxavNofRSPe"
      },
      "source": [
        "SENTIMENT_KEYS_NLTK = {'neutral': 'neu', 'negative': 'neg', 'positive': 'pos'}\n",
        "SENTIMENT_INDEXING = {'neutral': 0, 'negative': 1, 'positive': 2}\n",
        "SENTIMENT_WEIGHTS = {'neutral': 0, 'negative': -2, 'positive': 1}\n",
        "\n",
        "def get_sentiment_score_nltk(text, nlp_model):\n",
        "  \"\"\"\n",
        "  Computes the sentiment score for the given text, weighting each of the \n",
        "  sentiment types by a predefined weight.\n",
        "  \"\"\"\n",
        "  nltk_scores = nlp_model.polarity_scores(text)\n",
        "  score = 0\n",
        "  for sentiment_str, nltk_key in SENTIMENT_KEYS_NLTK.items():\n",
        "    score += nltk_scores[nltk_key] * SENTIMENT_WEIGHTS[sentiment_str] \n",
        "\n",
        "  return score\n",
        "\n",
        "\n",
        "def get_sentiment_score_absa(text, aspect, nlp_model):\n",
        "  task = nlp(text=(text), aspects=[aspect])\n",
        "  absa_scores = task.examples[0].scores\n",
        "\n",
        "  score = 0\n",
        "  for sentiment_str, ind in SENTIMENT_INDEXING.items():\n",
        "    score += scores[ind] * SENTIMENT_WEIGHTS[sentiment_str]\n",
        "\n",
        "  return score\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiuFpMDZtu7M"
      },
      "source": [
        "Now that we have defined the score functions, we need to extract the quotes for each of the node-node pairs depending on their mentions. For example, when computing the edge weight between nodes $i$ and $j$ (in that direction), we take into account all the nodes where the $i$ is recognized as the speaker, and in which node $j$ is mentioned (either by first or second name). The features that we collect are the mean sentiment score in all the quotes between $i$ and $j$, as well as their count.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG91QsrtsvAS"
      },
      "source": [
        "def get_mentions_from_list(quotes_list, look_for):\n",
        "  \"\"\"\n",
        "  Finds all the quotes that contain each of the words in the look_for list.\n",
        "  It returns a list of tuples, each of format (quote_text, target_word).\n",
        "  If a quote contains more than 1 word from the look_for list, only the first\n",
        "  one that was found is taken into account.\n",
        "  \"\"\"\n",
        "\n",
        "  # List of tuples of format (target_word, quote)\n",
        "  mentions = []\n",
        "  for quote in quotes_list:\n",
        "    for target_word in look_for:\n",
        "      if target_word.lower() in quote.lower():\n",
        "        mentions.append((quote, target_word))\n",
        "        break\n",
        "\n",
        "  return mentions\n",
        "\n",
        "\n",
        "def compute_edge_features(nodes_qids, quotes_per_node):\n",
        "  \"\"\"\n",
        "  Function that computes features for all the existing edges.\n",
        "  As input, it takes a mapping of the speaker(node) QIDs and the speaker names,\n",
        "  as well as the dictionary that contains all quotes for each node.\n",
        "  \"\"\"\n",
        "\n",
        "  # Predefining edges as tuples of node QIDs, resulting in \n",
        "  # the list of edges called edges_qids\n",
        "  qids_list = list(nodes_qids.keys())\n",
        "  edges_qids = []\n",
        "  for pair in itertools.product(qids_list, qids_list):\n",
        "    if pair[0] != pair[1]:\n",
        "      edges_qids.append(pair)\n",
        "\n",
        "  # For each edge (pair of nodes), we find all the quotes of interest\n",
        "  edge_features = {}\n",
        "  for (speaker_qid, mention_qid) in edges_qids:\n",
        "    print(f'\\nComputing features for edge {speaker_qid} - {mention_qid}')\n",
        "\n",
        "    # Split the full name of the target person into its first and second name\n",
        "    # (or however many there are) and look for both of those in the \n",
        "    # quotes of the current speaker\n",
        "    mention_name = nodes_qids[mention_qid]\n",
        "    look_for = mention_name.split()\n",
        "\n",
        "    # Find the quotes mentioning the names\n",
        "    curr_mentions = get_mentions_from_list(\n",
        "        quotes_per_node[speaker_qid], look_for\n",
        "        )\n",
        "\n",
        "    if len(curr_mentions) == 0:\n",
        "      print('No mentions for this edge. Skipping... \\n')\n",
        "      continue \n",
        "\n",
        "    print(f'Number of mentions {len(curr_mentions)}')\n",
        "\n",
        "    # Iterate through current mentions of interest, compute the above-defined \n",
        "    # sentiment score (for the NLTK model) and assign it to the edge \n",
        "    all_scores = []\n",
        "    for mention_iter, mention in enumerate(curr_mentions):\n",
        "      if mention_iter % 20 == 0:\n",
        "        print(f'Mention number {mention_iter}')\n",
        "\n",
        "      curr_score = get_sentiment_score_nltk(mention[0], sia)\n",
        "      all_scores.append(curr_score)\n",
        "      \n",
        "      # Assign the mean sentiment score and the quote count to the edge features\n",
        "      mean_score = np.mean(all_scores)\n",
        "      num_mentions = len(curr_mentions)\n",
        "\n",
        "      edge_features[(speaker_qid, mention_qid)] = {\n",
        "          'mean_sentiment': mean_score,\n",
        "          'num_mentions': num_mentions,\n",
        "          }\n",
        "\n",
        "  return edge_features\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j_kQ2T-fTPn",
        "outputId": "be809782-a921-4b45-e18a-65760ca7c41d"
      },
      "source": [
        "edge_features = compute_edge_features(nodes_qids, quotes_per_node)\n",
        "\n",
        "print('\\n\\nEdge features: \\n')\n",
        "# Print the edge features\n",
        "for key, val in edge_features.items():\n",
        "  print(nodes_qids[key[0]], nodes_qids[key[1]])\n",
        "  print(val, '\\n')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computing features for edge Q22686 - Q6294\n",
            "Number of mentions 87\n",
            "Mention number 0\n",
            "Mention number 20\n",
            "Mention number 40\n",
            "Mention number 60\n",
            "Mention number 80\n",
            "\n",
            "Computing features for edge Q22686 - Q6279\n",
            "Number of mentions 31\n",
            "Mention number 0\n",
            "Mention number 20\n",
            "\n",
            "Computing features for edge Q6294 - Q22686\n",
            "Number of mentions 43\n",
            "Mention number 0\n",
            "Mention number 20\n",
            "Mention number 40\n",
            "\n",
            "Computing features for edge Q6294 - Q6279\n",
            "Number of mentions 14\n",
            "Mention number 0\n",
            "\n",
            "Computing features for edge Q6279 - Q22686\n",
            "No mentions for this edge. Skipping... \n",
            "\n",
            "\n",
            "Computing features for edge Q6279 - Q6294\n",
            "Number of mentions 2\n",
            "Mention number 0\n",
            "\n",
            "\n",
            "Edge features: \n",
            "\n",
            "Donald Trump Hillary Clinton\n",
            "{'mean_sentiment': -0.07831034482758623, 'num_mentions': 87} \n",
            "\n",
            "Donald Trump Barack Obama\n",
            "{'mean_sentiment': -0.013967741935483861, 'num_mentions': 31} \n",
            "\n",
            "Hillary Clinton Donald Trump\n",
            "{'mean_sentiment': -0.13325581395348837, 'num_mentions': 43} \n",
            "\n",
            "Hillary Clinton Barack Obama\n",
            "{'mean_sentiment': -0.13135714285714287, 'num_mentions': 14} \n",
            "\n",
            "Barack Obama Hillary Clinton\n",
            "{'mean_sentiment': -0.025, 'num_mentions': 2} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOw7TxDO3ah7"
      },
      "source": [
        "## Conclusion \n",
        "After implementing our idea and examining it thoroughly, we conclude that (so far) it hasn't shown much promise, due to the fact that the sentiment analysis models haven't worked as we hoped they will. Namely, the model from NLTK is not specific enough for our use-case (given that it analyzes the whole sentence and is not aspect-based). On the other hand, the ABSA model that seemed like a great fit in theory is extremely slow and thus impossible to use in this setting, with this many data points (quotes).\n",
        "\n",
        "**ToDo** - find alternative models that also leverage the aspect-based sentiment analysis, but scale much better to the size of our dataset.\n",
        "\n",
        "### Too good to go 🍞\n",
        "\n",
        "We also tried to create a very naive and simple alternative to the aspect-based sentiment analysis, that would work at least partly well as ABSA itself, but using the NLTK model, thus fixing the execution time problem. What we did was the following:     \n",
        "* Given a quote and target word, we found all the occurences of the target word in the quote (let's say that it occurs $n$ times)\n",
        "* We split the quote into $n$ subquotes, each of them being an *epsilon-neighborhood* of each of the target word occurences\n",
        "* Finally, we computed the sentiment score for all of those subquotes and averaged them, arriving to the final score for the given quote\n",
        "\n",
        "Sadly, it didn't give us much improvement, but here's a part of that code anyways.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOTCbuzUmRez"
      },
      "source": [
        "def split_quote_into_subquotes(quote, target, eps=5):\n",
        "  \"\"\"\n",
        "  Function that splits the original quote into as many subquotes as \n",
        "  the number of the occurences of the target word in the original quote.\n",
        "  \"\"\"\n",
        "  words = quote.split(' ')\n",
        "  # Find the indexes the target word in the given quote\n",
        "  target_inds = [i for i, word in enumerate(words) if target in word]\n",
        "\n",
        "  # Iterate through the occurences of the target word and take\n",
        "  # the epsilon neighborhoods\n",
        "  subquotes = []\n",
        "  for target_ind in target_inds:\n",
        "    # Making sure we avoid index out of range\n",
        "    start_ind = max(0, target_ind - eps)\n",
        "    end_ind = min(len(words) - 1, target_ind + eps)\n",
        "\n",
        "    subquotes.append(' '.join(words[start_ind : end_ind + 1]))\n",
        "\n",
        "  return subquotes\n",
        "\n",
        "\n",
        "def get_sentiment_score_for_quote(quote, target, eps=4):\n",
        "  \"\"\"\n",
        "  Function that computes the final score for the given quote, first \n",
        "  splitting into subquotes and then averaging all the individual scores.\n",
        "  \"\"\"\n",
        "  subquotes = split_quote_into_subquotes(quote, target, eps=eps)\n",
        "\n",
        "  subquote_scores = []\n",
        "  for subquote in subquotes:\n",
        "    curr_score = get_sentiment_score_nltk(subquote)\n",
        "    subquote_scores.append(curr_score)\n",
        "      \n",
        "  return np.mean(subquote_scores)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}